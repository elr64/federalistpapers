{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Attribution on RNN Generated Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generated by recurrent neural networks trained on the Federalist Papers written by Hamilton, the papers written by Madison, and the papers written by Madison combined with the disputed papers, are analyzed using the author attribution models previously trained. The purpose of doing this is to observe whether the author attribution models correctly predict the author that each text was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the texts must be read in from the tsv file created from the output of the RNN models and separated into lists of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(generated_texts):\n",
    "    with open(generated_texts, \"r\") as texts:\n",
    "        hamilton=[]\n",
    "        madison=[]\n",
    "        madison_disputed=[]\n",
    "        for line in texts:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            author=fields[0]\n",
    "            if author == 'hamilton':\n",
    "                hamilton.append(fields[1])\n",
    "            if author == 'madison':\n",
    "                madison.append(fields[1])\n",
    "            if author == 'madison1':\n",
    "                madison_disputed.append(fields[1])\n",
    "    return hamilton, madison, madison_disputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same function words used to train the models are read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_function_words(resource_path): #reads in words from text file separated by new line\n",
    "    f_words = []\n",
    "    with open(resource_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                f_words.append(line.lower().strip())\n",
    "    return f_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature vectors for each of the texts on the function words must be created in the same format as the training data used to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vecs(test_texts, function_words): \n",
    "    #create matrix of zeros where row corresponds to paper and column to function word\n",
    "    test_features = np.zeros((len(test_texts),len(function_words)), dtype=np.int)\n",
    "    \n",
    "    #populate matrix with counts for each function word for each generated text\n",
    "    for i,text in enumerate(test_texts):\n",
    "        for j,function_word in enumerate(function_words):\n",
    "            text_tokens = text.lower().split()\n",
    "            count = len([w for w in text_tokens if w == function_words[j]])\n",
    "            test_features[i,j] = count\n",
    "    return test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previously trained author attribution models are loaded and predictions made for the RNN-generated texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predicts(test_features):\n",
    "    nb_mod=pickle.load(open(\"nb_mod.sav\", 'rb'))\n",
    "    preds=nb_mod.predict(test_features)\n",
    "    print(\"Naive Bayes Predictions\")\n",
    "    for pred in preds:\n",
    "        if pred == 0:\n",
    "            auth = \"Hamilton\"\n",
    "        else:\n",
    "            auth = \"Madison\"\n",
    "        print(f\"Predicted author: {auth}\")\n",
    "    knn_mod=pickle.load(open(\"knn_mod.sav\", 'rb'))\n",
    "    preds=knn_mod.predict(test_features)\n",
    "    print(\"K-Nearest Neighbors Predictions\")\n",
    "    for pred in preds:\n",
    "        if pred == 0:\n",
    "            auth = \"Hamilton\"\n",
    "        else:\n",
    "            auth = \"Madison\"\n",
    "        print(f\"Predicted author: {auth}\")\n",
    "    svm_mod=pickle.load(open(\"svm_mod.sav\", 'rb'))\n",
    "    test_feats=pd.DataFrame(test_features)\n",
    "    test_feats=test_feats.iloc[:,[57, 43, 59]]\n",
    "    preds=svm_mod.predict(test_feats)\n",
    "    print(\"SVM Predictions\")\n",
    "    for pred in preds:\n",
    "        if pred == 0:\n",
    "            auth = \"Hamilton\"\n",
    "        else:\n",
    "            auth = \"Madison\"\n",
    "        print(f\"Predicted author: {auth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the functions defined above are called to produce the predictions on each text by each author attribution model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(generated_texts, function_words):\n",
    "    hamilton, madison, madison_disputed = get_texts(generated_texts)\n",
    "    func_words=load_function_words(function_words)\n",
    "    hamilton_features=feature_vecs(hamilton, func_words)\n",
    "    madison_features=feature_vecs(madison, func_words)\n",
    "    madison_disputed_features=feature_vecs(madison_disputed, func_words)\n",
    "    print(\"Predictions for text generated by model trained on Hamilton papers\")\n",
    "    make_predicts(hamilton_features)\n",
    "    print(\"Predictions for text generated by model trained on Madison papers\")\n",
    "    make_predicts(madison_features)\n",
    "    print(\"Predictions for text generated by model trained on Madison and disputed papers\")\n",
    "    make_predicts(madison_disputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for text generated by model trained on Hamilton papers\n",
      "Naive Bayes Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "K-Nearest Neighbors Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "SVM Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predictions for text generated by model trained on Madison papers\n",
      "Naive Bayes Predictions\n",
      "Predicted author: Madison\n",
      "Predicted author: Madison\n",
      "Predicted author: Madison\n",
      "K-Nearest Neighbors Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "SVM Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predictions for text generated by model trained on Madison and disputed papers\n",
      "Naive Bayes Predictions\n",
      "Predicted author: Madison\n",
      "Predicted author: Madison\n",
      "Predicted author: Madison\n",
      "K-Nearest Neighbors Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "SVM Predictions\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n",
      "Predicted author: Hamilton\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='predicting author of rnn-generated text')\n",
    "    parser.add_argument('--path', type=str, default=\"generated_texts.tsv\",\n",
    "                        help='path to rnn-generated texts')\n",
    "    parser.add_argument('--function_words_path', type=str, default=\"function_words.txt\",\n",
    "                        help='path to the list of words to use as features')\n",
    "    args =     parser.parse_known_args()[0]\n",
    "\n",
    "    main(args.path, args.function_words_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naïve Bayes model correctly predicts the author of all 9 of the generated texts. Both the K-Nearest Neighbor and SVM models predict Hamilton each time, making them respectively 33% accurate. It is interesting to note the discrepency in accuracy between the Naïve Bayes model and SVM model, which were much closer on the known papers used in training and the disputed papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
